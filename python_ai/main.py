"""
===========================================
SmartSpend AI Server (FastAPI)
===========================================
μ‹¤ν–‰: python main.py
URL: http://localhost:8000
API λ¬Έμ„: http://localhost:8000/docs
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import Optional
import os

from app.services.ollama_service import OllamaService
from app.services.attendance_service import AttendanceService
from app.services.performance_service import PerformanceService
# β… μ¶”κ°€: μμμ¦ OCR λΌμ°ν„° import (μμμ¦ OCR ν†µν•©)
from app.api.receipt_router import router as receipt_router

# FastAPI μ•± μƒμ„±
app = FastAPI(
    title="SmartSpend AI Server",
    description="μ¶κ²° κ΄€λ¦¬ AI μ±—λ΄‡ μ„λ²„",
    version="1.0.0"
)

# CORS μ„¤μ • (React 3000λ² ν¬νΈ ν—μ©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# μ„λΉ„μ¤ μΈμ¤ν„΄μ¤
ollama_service = OllamaService()
attendance_service = AttendanceService(ollama_service)
performance_service = PerformanceService(ollama_service)

# β… μ¶”κ°€: μμμ¦ OCR λΌμ°ν„° λ“±λ΅ (μμμ¦ OCR ν†µν•©)
# /api/ai/receipt/extract μ—”λ“ν¬μΈνΈκ°€ μ¶”κ°€λ¨
app.include_router(receipt_router)

# DTO μ •μ
class AttendanceAiRequest(BaseModel):
    prompt: str  # μ‚¬μ©μ μ…λ ¥

class AttendanceAiResponse(BaseModel):
    ok: bool
    message: str
    summary: Optional[str] = None
    hasFile: bool = False
    downloadUrl: Optional[str] = None
    fileName: Optional[str] = None

# λ¶€μ„ μ‹¤μ  DTO
class PerformanceAiRequest(BaseModel):
    prompt: str  # μ‚¬μ©μ μ…λ ¥

class PerformanceAiResponse(BaseModel):
    ok: bool
    message: str
    summary: Optional[str] = None
    chartImage: Optional[str] = None  # Base64 μ΄λ―Έμ§€

# API μ—”λ“ν¬μΈνΈ
@app.get("/")
def health_check():
    return {"status": "ok", "message": "SmartSpend AI Server is running!"}

@app.post("/api/ai/attendance", response_model=AttendanceAiResponse)
def process_attendance_query(request: AttendanceAiRequest):
    """μ¶κ²° AI λ©”μΈ μ—”λ“ν¬μΈνΈ"""
    try:
        result = attendance_service.process_query(request.prompt)
        return AttendanceAiResponse(**result)
    except Exception as e:
        return AttendanceAiResponse(
            ok=False,
            message=f"μ¤λ¥: {str(e)}",
            hasFile=False
        )

@app.get("/api/ai/attendance/download/{filename}")
def download_file(filename: str):
    """μ—‘μ…€ νμΌ λ‹¤μ΄λ΅λ“"""
    file_path = f"generated/{filename}"
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="νμΌ μ—†μ")
    return FileResponse(path=file_path, filename=filename)

# ========== λ¶€μ„ μ‹¤μ  API ==========
@app.post("/api/ai/performance", response_model=PerformanceAiResponse)
def process_performance_query(request: PerformanceAiRequest):
    """λ¶€μ„ μ‹¤μ  λΉ„κµ AI μ—”λ“ν¬μΈνΈ"""
    try:
        result = performance_service.process_query(request.prompt)
        return PerformanceAiResponse(**result)
    except Exception as e:
        print(f"[Performance API Error] {e}")
        return PerformanceAiResponse(
            ok=False,
            message=f"μ¤λ¥: {str(e)}",
            summary=None,
            chartImage=None
        )

# μ„λ²„ μ‹¤ν–‰
if __name__ == "__main__":
    import uvicorn
    print("π€ SmartSpend AI Server: http://localhost:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)